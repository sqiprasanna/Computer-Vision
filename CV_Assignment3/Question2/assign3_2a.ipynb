{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assign3_2a.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "rquheDGHE62b",
        "outputId": "5a5f52b1-4d65-4117-b03f-d2a3f3b77802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w8MW8GYrFAej",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import scipy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import io as sio\n",
        "from scipy import ndimage, misc\n",
        "import csv\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mjZUWUrCKWN_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JmFtVP2UFVBz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.classifier[6].in_features\n",
        "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "    input_size = 224\n",
        "\n",
        "   \n",
        "    return model_ft, input_size\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-kvz5g4XTbDj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class create_dataset(Dataset):\n",
        "   \n",
        "    def __init__(self,root_dir,total_count, csv_file, transform=None):\n",
        "      \n",
        "      \n",
        "        self.root_dir = root_dir\n",
        "        self.total_count = total_count\n",
        "        self.csv_file = np.array(pd.read_csv(csv_file,header=None))[0]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_count\n",
        "\n",
        "    def __getitem__(self, image_no):\n",
        "        img_name = os.path.join(self.root_dir,\n",
        "                                str(image_no+1)+\".jpg\")\n",
        "        image = Image.open(img_name)\n",
        "        sample = {'image': image, 'label': self.csv_file[image_no]-1}\n",
        "\n",
        "        if self.transform:\n",
        "            sample['image'] = self.transform(sample['image'])\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8j6xuwL8sVhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "b7e15f07-d2a2-4c7a-f0f1-41cf9a92443b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "num_classes = 8\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "feature_extract = True\n",
        "\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "alexnet.classifier[6] = nn.Linear(4096,8)\n",
        "\n",
        "alexnet.eval()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace)\n",
              "    (3): Dropout(p=0.5)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace)\n",
              "    (6): Linear(in_features=4096, out_features=8, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d-KdkZBEUBcD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels = np.array(pd.read_csv('/content/drive/My Drive/CV_assign3_dataset/train_labels.csv',header =None))[0]\n",
        "test_labels = np.array(pd.read_csv('/content/drive/My Drive/CV_assign3_dataset/test_labels.csv',header =None))[0]\n",
        "\n",
        "trainDataset = create_dataset('/content/drive/My Drive/CV_assign3_dataset/train',1888,'/content/drive/My Drive/CV_assign3_dataset/train_labels.csv',transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]))\n",
        "\n",
        "testDataset = create_dataset('/content/drive/My Drive/CV_assign3_dataset/test',800,'/content/drive/My Drive/CV_assign3_dataset/test_labels.csv',transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q6JbuZhCFVF6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "af0b1c89-36e3-4fad-9288-329f23fc7538"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model_ft, input_size = initialize_model(8, feature_extract, use_pretrained=True)\n",
        "print(model_ft)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Dropout(p=0.5)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): Linear(in_features=4096, out_features=8, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bR2cb0R_Lc9T",
        "outputId": "049d3dfa-e6e3-440b-c4f5-34f53dbd921e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "\n",
        "trainDataloader = torch.utils.data.DataLoader(trainDataset,batch_size = 8, shuffle = True, num_workers=4)\n",
        "testDataloader = torch.utils.data.DataLoader(testDataset,batch_size = 8, shuffle = True, num_workers=4)\n",
        "Dataloaders_dict = {trainDataloader,testDataloader}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mI4GhKz9O93b",
        "outputId": "8eedebfc-30a2-4345-8deb-ee4829ae6786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wAGSFgIrLwCd",
        "outputId": "3c47d320-02c3-400b-bc28-38c7f5f7c762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5899
        }
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(15):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainDataloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data['image'],data['label']\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer_ft.zero_grad()\n",
        "        outputs = model_ft(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_ft.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:    # print every 10 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 10))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Training done')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 1.706\n",
            "[1,    20] loss: 0.663\n",
            "[1,    30] loss: 0.684\n",
            "[1,    40] loss: 0.348\n",
            "[1,    50] loss: 0.473\n",
            "[1,    60] loss: 0.355\n",
            "[1,    70] loss: 0.594\n",
            "[1,    80] loss: 0.435\n",
            "[1,    90] loss: 0.377\n",
            "[1,   100] loss: 0.539\n",
            "[1,   110] loss: 0.482\n",
            "[1,   120] loss: 0.412\n",
            "[1,   130] loss: 0.467\n",
            "[1,   140] loss: 0.272\n",
            "[1,   150] loss: 0.492\n",
            "[1,   160] loss: 0.485\n",
            "[1,   170] loss: 0.318\n",
            "[1,   180] loss: 0.546\n",
            "[1,   190] loss: 0.358\n",
            "[1,   200] loss: 0.524\n",
            "[1,   210] loss: 0.419\n",
            "[1,   220] loss: 0.580\n",
            "[1,   230] loss: 0.520\n",
            "[2,    10] loss: 0.362\n",
            "[2,    20] loss: 0.421\n",
            "[2,    30] loss: 0.232\n",
            "[2,    40] loss: 0.471\n",
            "[2,    50] loss: 0.688\n",
            "[2,    60] loss: 0.327\n",
            "[2,    70] loss: 0.596\n",
            "[2,    80] loss: 0.443\n",
            "[2,    90] loss: 0.437\n",
            "[2,   100] loss: 0.441\n",
            "[2,   110] loss: 0.533\n",
            "[2,   120] loss: 0.377\n",
            "[2,   130] loss: 0.330\n",
            "[2,   140] loss: 0.649\n",
            "[2,   150] loss: 0.363\n",
            "[2,   160] loss: 0.312\n",
            "[2,   170] loss: 0.266\n",
            "[2,   180] loss: 0.251\n",
            "[2,   190] loss: 0.403\n",
            "[2,   200] loss: 0.294\n",
            "[2,   210] loss: 0.305\n",
            "[2,   220] loss: 0.382\n",
            "[2,   230] loss: 0.470\n",
            "[3,    10] loss: 0.414\n",
            "[3,    20] loss: 0.360\n",
            "[3,    30] loss: 0.291\n",
            "[3,    40] loss: 0.280\n",
            "[3,    50] loss: 0.423\n",
            "[3,    60] loss: 0.415\n",
            "[3,    70] loss: 0.175\n",
            "[3,    80] loss: 0.212\n",
            "[3,    90] loss: 0.311\n",
            "[3,   100] loss: 0.212\n",
            "[3,   110] loss: 0.718\n",
            "[3,   120] loss: 0.381\n",
            "[3,   130] loss: 0.448\n",
            "[3,   140] loss: 0.556\n",
            "[3,   150] loss: 0.390\n",
            "[3,   160] loss: 0.352\n",
            "[3,   170] loss: 0.434\n",
            "[3,   180] loss: 0.362\n",
            "[3,   190] loss: 0.269\n",
            "[3,   200] loss: 0.282\n",
            "[3,   210] loss: 0.621\n",
            "[3,   220] loss: 0.669\n",
            "[3,   230] loss: 0.365\n",
            "[4,    10] loss: 0.379\n",
            "[4,    20] loss: 0.139\n",
            "[4,    30] loss: 0.500\n",
            "[4,    40] loss: 0.384\n",
            "[4,    50] loss: 0.370\n",
            "[4,    60] loss: 0.338\n",
            "[4,    70] loss: 0.493\n",
            "[4,    80] loss: 0.287\n",
            "[4,    90] loss: 0.444\n",
            "[4,   100] loss: 0.309\n",
            "[4,   110] loss: 0.528\n",
            "[4,   120] loss: 0.286\n",
            "[4,   130] loss: 0.333\n",
            "[4,   140] loss: 0.216\n",
            "[4,   150] loss: 0.401\n",
            "[4,   160] loss: 0.202\n",
            "[4,   170] loss: 0.461\n",
            "[4,   180] loss: 0.298\n",
            "[4,   190] loss: 0.523\n",
            "[4,   200] loss: 0.226\n",
            "[4,   210] loss: 0.602\n",
            "[4,   220] loss: 0.536\n",
            "[4,   230] loss: 0.456\n",
            "[5,    10] loss: 0.221\n",
            "[5,    20] loss: 0.237\n",
            "[5,    30] loss: 0.340\n",
            "[5,    40] loss: 0.276\n",
            "[5,    50] loss: 0.215\n",
            "[5,    60] loss: 0.464\n",
            "[5,    70] loss: 0.305\n",
            "[5,    80] loss: 0.339\n",
            "[5,    90] loss: 0.218\n",
            "[5,   100] loss: 0.653\n",
            "[5,   110] loss: 0.492\n",
            "[5,   120] loss: 0.298\n",
            "[5,   130] loss: 0.256\n",
            "[5,   140] loss: 0.372\n",
            "[5,   150] loss: 0.475\n",
            "[5,   160] loss: 0.447\n",
            "[5,   170] loss: 0.407\n",
            "[5,   180] loss: 0.761\n",
            "[5,   190] loss: 0.450\n",
            "[5,   200] loss: 0.175\n",
            "[5,   210] loss: 0.498\n",
            "[5,   220] loss: 0.197\n",
            "[5,   230] loss: 0.209\n",
            "[6,    10] loss: 0.187\n",
            "[6,    20] loss: 0.214\n",
            "[6,    30] loss: 0.440\n",
            "[6,    40] loss: 0.212\n",
            "[6,    50] loss: 0.365\n",
            "[6,    60] loss: 0.266\n",
            "[6,    70] loss: 0.419\n",
            "[6,    80] loss: 0.534\n",
            "[6,    90] loss: 0.301\n",
            "[6,   100] loss: 0.426\n",
            "[6,   110] loss: 0.347\n",
            "[6,   120] loss: 0.325\n",
            "[6,   130] loss: 0.262\n",
            "[6,   140] loss: 0.252\n",
            "[6,   150] loss: 0.545\n",
            "[6,   160] loss: 0.379\n",
            "[6,   170] loss: 0.216\n",
            "[6,   180] loss: 0.357\n",
            "[6,   190] loss: 0.247\n",
            "[6,   200] loss: 0.320\n",
            "[6,   210] loss: 0.280\n",
            "[6,   220] loss: 0.286\n",
            "[6,   230] loss: 0.417\n",
            "[7,    10] loss: 0.330\n",
            "[7,    20] loss: 0.171\n",
            "[7,    30] loss: 0.252\n",
            "[7,    40] loss: 0.299\n",
            "[7,    50] loss: 0.156\n",
            "[7,    60] loss: 0.266\n",
            "[7,    70] loss: 0.428\n",
            "[7,    80] loss: 0.335\n",
            "[7,    90] loss: 0.315\n",
            "[7,   100] loss: 0.578\n",
            "[7,   110] loss: 0.279\n",
            "[7,   120] loss: 0.395\n",
            "[7,   130] loss: 0.206\n",
            "[7,   140] loss: 0.370\n",
            "[7,   150] loss: 0.330\n",
            "[7,   160] loss: 0.245\n",
            "[7,   170] loss: 0.299\n",
            "[7,   180] loss: 0.332\n",
            "[7,   190] loss: 0.146\n",
            "[7,   200] loss: 0.260\n",
            "[7,   210] loss: 0.233\n",
            "[7,   220] loss: 0.279\n",
            "[7,   230] loss: 0.270\n",
            "[8,    10] loss: 0.356\n",
            "[8,    20] loss: 0.246\n",
            "[8,    30] loss: 0.414\n",
            "[8,    40] loss: 0.263\n",
            "[8,    50] loss: 0.404\n",
            "[8,    60] loss: 0.243\n",
            "[8,    70] loss: 0.304\n",
            "[8,    80] loss: 0.114\n",
            "[8,    90] loss: 0.352\n",
            "[8,   100] loss: 0.244\n",
            "[8,   110] loss: 0.469\n",
            "[8,   120] loss: 0.274\n",
            "[8,   130] loss: 0.324\n",
            "[8,   140] loss: 0.204\n",
            "[8,   150] loss: 0.522\n",
            "[8,   160] loss: 0.262\n",
            "[8,   170] loss: 0.380\n",
            "[8,   180] loss: 0.392\n",
            "[8,   190] loss: 0.349\n",
            "[8,   200] loss: 0.314\n",
            "[8,   210] loss: 0.574\n",
            "[8,   220] loss: 0.231\n",
            "[8,   230] loss: 0.172\n",
            "[9,    10] loss: 0.327\n",
            "[9,    20] loss: 0.224\n",
            "[9,    30] loss: 0.282\n",
            "[9,    40] loss: 0.202\n",
            "[9,    50] loss: 0.503\n",
            "[9,    60] loss: 0.343\n",
            "[9,    70] loss: 0.339\n",
            "[9,    80] loss: 0.361\n",
            "[9,    90] loss: 0.202\n",
            "[9,   100] loss: 0.411\n",
            "[9,   110] loss: 0.447\n",
            "[9,   120] loss: 0.290\n",
            "[9,   130] loss: 0.311\n",
            "[9,   140] loss: 0.153\n",
            "[9,   150] loss: 0.282\n",
            "[9,   160] loss: 0.273\n",
            "[9,   170] loss: 0.253\n",
            "[9,   180] loss: 0.250\n",
            "[9,   190] loss: 0.295\n",
            "[9,   200] loss: 0.502\n",
            "[9,   210] loss: 0.285\n",
            "[9,   220] loss: 0.283\n",
            "[9,   230] loss: 0.240\n",
            "[10,    10] loss: 0.177\n",
            "[10,    20] loss: 0.250\n",
            "[10,    30] loss: 0.414\n",
            "[10,    40] loss: 0.296\n",
            "[10,    50] loss: 0.393\n",
            "[10,    60] loss: 0.245\n",
            "[10,    70] loss: 0.329\n",
            "[10,    80] loss: 0.300\n",
            "[10,    90] loss: 0.297\n",
            "[10,   100] loss: 0.419\n",
            "[10,   110] loss: 0.391\n",
            "[10,   120] loss: 0.191\n",
            "[10,   130] loss: 0.323\n",
            "[10,   140] loss: 0.245\n",
            "[10,   150] loss: 0.202\n",
            "[10,   160] loss: 0.227\n",
            "[10,   170] loss: 0.398\n",
            "[10,   180] loss: 0.115\n",
            "[10,   190] loss: 0.595\n",
            "[10,   200] loss: 0.494\n",
            "[10,   210] loss: 0.284\n",
            "[10,   220] loss: 0.125\n",
            "[10,   230] loss: 0.198\n",
            "[11,    10] loss: 0.152\n",
            "[11,    20] loss: 0.386\n",
            "[11,    30] loss: 0.362\n",
            "[11,    40] loss: 0.215\n",
            "[11,    50] loss: 0.138\n",
            "[11,    60] loss: 0.534\n",
            "[11,    70] loss: 0.186\n",
            "[11,    80] loss: 0.304\n",
            "[11,    90] loss: 0.387\n",
            "[11,   100] loss: 0.283\n",
            "[11,   110] loss: 0.183\n",
            "[11,   120] loss: 0.419\n",
            "[11,   130] loss: 0.162\n",
            "[11,   140] loss: 0.142\n",
            "[11,   150] loss: 0.338\n",
            "[11,   160] loss: 0.268\n",
            "[11,   170] loss: 0.181\n",
            "[11,   180] loss: 0.304\n",
            "[11,   190] loss: 0.130\n",
            "[11,   200] loss: 0.219\n",
            "[11,   210] loss: 0.178\n",
            "[11,   220] loss: 0.572\n",
            "[11,   230] loss: 0.323\n",
            "[12,    10] loss: 0.420\n",
            "[12,    20] loss: 0.230\n",
            "[12,    30] loss: 0.261\n",
            "[12,    40] loss: 0.405\n",
            "[12,    50] loss: 0.349\n",
            "[12,    60] loss: 0.316\n",
            "[12,    70] loss: 0.138\n",
            "[12,    80] loss: 0.274\n",
            "[12,    90] loss: 0.307\n",
            "[12,   100] loss: 0.413\n",
            "[12,   110] loss: 0.344\n",
            "[12,   120] loss: 0.284\n",
            "[12,   130] loss: 0.394\n",
            "[12,   140] loss: 0.266\n",
            "[12,   150] loss: 0.205\n",
            "[12,   160] loss: 0.222\n",
            "[12,   170] loss: 0.283\n",
            "[12,   180] loss: 0.474\n",
            "[12,   190] loss: 0.135\n",
            "[12,   200] loss: 0.403\n",
            "[12,   210] loss: 0.440\n",
            "[12,   220] loss: 0.641\n",
            "[12,   230] loss: 0.238\n",
            "[13,    10] loss: 0.327\n",
            "[13,    20] loss: 0.318\n",
            "[13,    30] loss: 0.409\n",
            "[13,    40] loss: 0.208\n",
            "[13,    50] loss: 0.305\n",
            "[13,    60] loss: 0.157\n",
            "[13,    70] loss: 0.246\n",
            "[13,    80] loss: 0.238\n",
            "[13,    90] loss: 0.323\n",
            "[13,   100] loss: 0.284\n",
            "[13,   110] loss: 0.222\n",
            "[13,   120] loss: 0.225\n",
            "[13,   130] loss: 0.314\n",
            "[13,   140] loss: 0.154\n",
            "[13,   150] loss: 0.313\n",
            "[13,   160] loss: 0.338\n",
            "[13,   170] loss: 0.351\n",
            "[13,   180] loss: 0.412\n",
            "[13,   190] loss: 0.397\n",
            "[13,   200] loss: 0.183\n",
            "[13,   210] loss: 0.355\n",
            "[13,   220] loss: 0.402\n",
            "[13,   230] loss: 0.179\n",
            "[14,    10] loss: 0.233\n",
            "[14,    20] loss: 0.339\n",
            "[14,    30] loss: 0.403\n",
            "[14,    40] loss: 0.176\n",
            "[14,    50] loss: 0.189\n",
            "[14,    60] loss: 0.512\n",
            "[14,    70] loss: 0.232\n",
            "[14,    80] loss: 0.330\n",
            "[14,    90] loss: 0.201\n",
            "[14,   100] loss: 0.223\n",
            "[14,   110] loss: 0.366\n",
            "[14,   120] loss: 0.240\n",
            "[14,   130] loss: 0.230\n",
            "[14,   140] loss: 0.197\n",
            "[14,   150] loss: 0.231\n",
            "[14,   160] loss: 0.268\n",
            "[14,   170] loss: 0.148\n",
            "[14,   180] loss: 0.328\n",
            "[14,   190] loss: 0.337\n",
            "[14,   200] loss: 0.289\n",
            "[14,   210] loss: 0.236\n",
            "[14,   220] loss: 0.188\n",
            "[14,   230] loss: 0.237\n",
            "[15,    10] loss: 0.155\n",
            "[15,    20] loss: 0.134\n",
            "[15,    30] loss: 0.450\n",
            "[15,    40] loss: 0.279\n",
            "[15,    50] loss: 0.083\n",
            "[15,    60] loss: 0.181\n",
            "[15,    70] loss: 0.210\n",
            "[15,    80] loss: 0.266\n",
            "[15,    90] loss: 0.311\n",
            "[15,   100] loss: 0.307\n",
            "[15,   110] loss: 0.173\n",
            "[15,   120] loss: 0.323\n",
            "[15,   130] loss: 0.323\n",
            "[15,   140] loss: 0.498\n",
            "[15,   150] loss: 0.150\n",
            "[15,   160] loss: 0.261\n",
            "[15,   170] loss: 0.247\n",
            "[15,   180] loss: 0.362\n",
            "[15,   190] loss: 0.273\n",
            "[15,   200] loss: 0.343\n",
            "[15,   210] loss: 0.210\n",
            "[15,   220] loss: 0.220\n",
            "[15,   230] loss: 0.404\n",
            "Training done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6S6nMMA88gUz",
        "outputId": "7dab30b7-e3d9-4e01-bb32-cf1af43f1c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(testDataloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data['image'],data['label']\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_ft(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "print('Accuracy of the network on the 800 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 800 test images: 90 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RC5dstrM1yl2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}